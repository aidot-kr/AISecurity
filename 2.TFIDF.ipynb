{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2주차 2차시 - 텍스트 데이터 수집\n",
    "# 무료로 수집가능한 Corpus : http://www.nltk.org/howto/corpus.html\n",
    "\n",
    "# 유닛2, 페이지1 텍스트데이터 수집(1)\n",
    "* 말뭉치(Corpus)의 사용사례\n",
    " - NLTK(Natural Language Toolkit)패키지는 실무 및 연구용을 활용이 가능한 자연어 처리 패키지\n",
    " - 말뭉치, 토큰 생성, 형태소 분석, 품사 태깅에 사용할 수 있음\n",
    " \n",
    "* NLTK 말뭉치 유형 예시\n",
    " - brown : 약 100만 단어의 묶음 샘플로 브라운대학교에서 표준적 영어문장을 정리함\n",
    " - gutenberg : 저작권이 말소된 문학작품의 샘플\n",
    " - names : 8000개의 남성과 여성의 이름 리스트\n",
    " - words : 가장 빈번하게 사용하는 영어 단어 23만 5000개\n",
    " - stopwords : 14개 유형의 언어가 지원되며, 가장 일반적인 불용어(stop word) 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지2 텍스트 데이터 수집(2)\n",
    "* NLTK에서 제공되는 말뭉치(Corpus)를 조회하고, \"영화리뷰\"와 관련된 말뭉치를 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_LazyModule__lazymodule_globals', '_LazyModule__lazymodule_import', '_LazyModule__lazymodule_init', '_LazyModule__lazymodule_loaded', '_LazyModule__lazymodule_locals', '_LazyModule__lazymodule_name', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "\n",
    "print(dir(nltk.corpus))\n",
    "nltk.download(\"movie_reviews\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지3 텍스트 데이터 수집(3)\n",
    "\n",
    "* 영화리뷰 코퍼스의 파일 리스트 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileList = nltk.corpus.movie_reviews.fileids()\n",
    "len(fileList)\n",
    "fileList[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전체 영화리뷰 목록 중 부정적 리뷰의견 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
      "what's the deal ? \n",
      "watch the movie and \" sorta \" find out . . . \n",
      "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \n",
      "which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn't snag this one correctly . \n",
      "they seem to have taken this pretty neat concept , but executed it terribly . \n",
      "so what are the problems with the movie ? \n",
      "well , its main problem is that it's simply too jumbled . \n",
      "it starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what's going on . \n",
      "there are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \n",
      "now i personally don't mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film's biggest problem . \n",
      "it's obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \n",
      "and do they make things entertaining , thrilling or even engaging , in the meantime ? \n",
      "not really . \n",
      "the sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn't the make the film all that more entertaining . \n",
      "i guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \n",
      "i mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \n",
      "okay , we get it . . . there \n",
      "are people chasing her and we don't know who they are . \n",
      "do we really need to see it over and over again ? \n",
      "how about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \n",
      "apparently , the studio took this film away from its director and chopped it up themselves , and it shows . \n",
      "there might've been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \n",
      "the actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \n",
      "but my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character's unraveling . \n",
      "overall , the film doesn't stick because it doesn't entertain , it's confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \n",
      "oh , and by the way , this is not a horror or teen slasher flick . . . it's \n",
      "just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \n",
      "it also wrapped production two years ago and has been sitting on the shelves ever since . \n",
      "whatever . . . skip \n",
      "it ! \n",
      "where's joblo coming from ? \n",
      "a nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_txt1 = nltk.corpus.movie_reviews.raw(\"neg/cv000_29416.txt\")\n",
    "print(review_txt1[:4043])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지4 텍스트 데이터 수집(4)\n",
    "* 모델기반의 클러스터링을 위해 TF-IDF를 사용하는 예제\n",
    " - Python의 활용하여 TF, DF, TF-IDF 계산 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는', '중이다', '있다', '예정이다', '공간에', '작업', '나의', '그', '내일도', '공간이며', '여기는'}\n"
     ]
    }
   ],
   "source": [
    "# 말뭉치(Corpus)를 통합하여 단어집합 구성\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "# 분석을 위해 수집된 말뭉치(Corpus)를 입력\n",
    "text_corpus = ['여기는 나의 작업 공간이며 나는 작업 중이다', '나는 그 작업 공간에 있다', '내일도 작업 예정이다' ]\n",
    "\n",
    "# 각각의 문서에서 단어를 추출\n",
    "text1_list = text_corpus[0].split(\" \")\n",
    "text2_list = text_corpus[1].split(\" \")\n",
    "text3_list = text_corpus[2].split(\" \")\n",
    "\n",
    "# 공통적으로 중복된 단어를 제거, 제거전 15개의 단어\n",
    "doc_set= set(text1_list).union(set(text2_list)).union(set(text3_list))\n",
    "\n",
    "# 4개의 중복 단어를 제거하고 14개의 단어집합(Set) 구성\n",
    "print(doc_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지5 텍스트 데이터 수집(5)\n",
    "\n",
    "* Python의 활용하여 TF, DF, TF-IDF 계산 (2)\n",
    " - doc_set의 전체 단어집합을 딕셔너리를 생성하며 값은 모두 0으로 저장하고, 빈도 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 0, '중이다': 0, '있다': 0, '예정이다': 0, '공간에': 0, '작업': 0, '나의': 0, '그': 0, '내일도': 0, '공간이며': 0, '여기는': 0}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# dict.fromkeys는 키가 들어있는 리스트를 넣으면 딕셔너리를 생성\n",
    "text1_dict = dict.fromkeys(doc_set, 0) \n",
    "text2_dict = dict.fromkeys(doc_set, 0)\n",
    "text3_dict = dict.fromkeys(doc_set, 0)\n",
    "\n",
    "# 딕셔너리는 키-값을 쌍으로 관리 용이\n",
    "print(text1_dict)\n",
    "print(text1_dict['공간이며'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 1, '중이다': 1, '있다': 0, '예정이다': 0, '공간에': 0, '작업': 2, '나의': 1, '그': 0, '내일도': 0, '공간이며': 1, '여기는': 1}\n"
     ]
    }
   ],
   "source": [
    "# 문서별로 해당 단어가 확인되면 리스트의 값을 1개씩 증가\n",
    "for text_word in text1_list:\n",
    "    text1_dict[text_word]+=1\n",
    "    \n",
    "for text_word in text2_list:\n",
    "    text2_dict[text_word]+=1\n",
    "    \n",
    "for text_word in text3_list:\n",
    "    text3_dict[text_word]+=1\n",
    "\n",
    "print(text1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>중이다</th>\n",
       "      <th>있다</th>\n",
       "      <th>예정이다</th>\n",
       "      <th>공간에</th>\n",
       "      <th>작업</th>\n",
       "      <th>나의</th>\n",
       "      <th>그</th>\n",
       "      <th>내일도</th>\n",
       "      <th>공간이며</th>\n",
       "      <th>여기는</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   나는  중이다  있다  예정이다  공간에  작업  나의  그  내일도  공간이며  여기는\n",
       "0   1    1   0     0    0   2   1  0    0     1    1\n",
       "1   1    0   1     0    1   1   0  1    0     0    0\n",
       "2   0    0   0     1    0   1   0  0    1     0    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서별 단어빈도가 확인 리스트를 하나의 데이터프레임으로 합산\n",
    "pd.DataFrame([text1_dict, text2_dict, text3_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지6 텍스트 데이터 수집(6)\n",
    "\n",
    "* Python의 활용하여 TF, DF, TF-IDF 계산 (3)\n",
    "  - TF는 각 문서에서의 해당 단어의 빈도로 계산 \n",
    "  - 해당 단어 개수 / 해당 문서 전체 단어 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>중이다</th>\n",
       "      <th>있다</th>\n",
       "      <th>예정이다</th>\n",
       "      <th>공간에</th>\n",
       "      <th>작업</th>\n",
       "      <th>나의</th>\n",
       "      <th>그</th>\n",
       "      <th>내일도</th>\n",
       "      <th>공간이며</th>\n",
       "      <th>여기는</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         나는       중이다   있다      예정이다  공간에        작업        나의    그       내일도  \\\n",
       "0  0.142857  0.142857  0.0  0.000000  0.0  0.285714  0.142857  0.0  0.000000   \n",
       "1  0.200000  0.000000  0.2  0.000000  0.2  0.200000  0.000000  0.2  0.000000   \n",
       "2  0.000000  0.000000  0.0  0.333333  0.0  0.333333  0.000000  0.0  0.333333   \n",
       "\n",
       "       공간이며       여기는  \n",
       "0  0.142857  0.142857  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF를 구하기 위한 함수 정의\n",
    "def getTF(temp_dic, temp_list):\n",
    "    tfDict = {}\n",
    "    wordCnt = len(temp_list)\n",
    "    for word_str, count in temp_dic.items():\n",
    "        tfDict[word_str] = count/float(wordCnt)\n",
    "    return tfDict\n",
    "\n",
    "# TF함수를 사용하여 각 문서 단어별 TF를 계산\n",
    "text1_tfDict = getTF(text1_dict, text1_list)\n",
    "text2_tfDict = getTF(text2_dict, text2_list)\n",
    "text3_tfDict = getTF(text3_dict, text3_list)\n",
    "\n",
    "# 전체 문서를 표형태의 데이터프레임으로 표현\n",
    "tf_df= pd.DataFrame([text1_tfDict, text2_tfDict, text3_tfDict])\n",
    "tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지7 텍스트 데이터 수집(7)\n",
    "\n",
    "* Python의 활용하여 TF, DF, TF-IDF 계산 (4)\n",
    "  - IDF는 전체 문서 중 특정 문서에서만 출현하는 단어를 추출\n",
    "  - log(전체 문서 수 / 해당 단어가 포함된 문서 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'나는': 0.17609125905568124,\n",
       " '중이다': 0.47712125471966244,\n",
       " '있다': 0.47712125471966244,\n",
       " '예정이다': 0.47712125471966244,\n",
       " '공간에': 0.47712125471966244,\n",
       " '작업': 0.0,\n",
       " '나의': 0.47712125471966244,\n",
       " '그': 0.47712125471966244,\n",
       " '내일도': 0.47712125471966244,\n",
       " '공간이며': 0.47712125471966244,\n",
       " '여기는': 0.47712125471966244}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDF를 구하기 위한 함수 정의\n",
    "def getIDF(temp_dict):\n",
    "    tmp = {}\n",
    "    totalCnt = len(temp_dict)\n",
    "    \n",
    "    tmp = dict.fromkeys(temp_dict[0].keys(), 0)\n",
    "    for doc in temp_dict:\n",
    "        for strword, cntword in doc.items():\n",
    "            if cntword > 0:\n",
    "                tmp[strword] += 1\n",
    "    \n",
    "    for sWord, intCnt in tmp.items():\n",
    "        tmp[sWord] = math.log10(totalCnt / float(intCnt))\n",
    "        \n",
    "    return tmp\n",
    "\n",
    "# 전체문서를 입력 값으로 getIDF함수를 통해서 계산\n",
    "idf_dict = getIDF([text1_dict, text2_dict, text3_dict])\n",
    "idf_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지8 텍스트 데이터 수집(8)\n",
    "\n",
    "* Python의 활용하여 TF, DF, TF-IDF 계산 (5)\n",
    "  - TF-IDF는 TF와 IDF를 합산하여 계산  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>중이다</th>\n",
       "      <th>있다</th>\n",
       "      <th>예정이다</th>\n",
       "      <th>공간에</th>\n",
       "      <th>작업</th>\n",
       "      <th>나의</th>\n",
       "      <th>그</th>\n",
       "      <th>내일도</th>\n",
       "      <th>공간이며</th>\n",
       "      <th>여기는</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025156</td>\n",
       "      <td>0.06816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.06816</td>\n",
       "      <td>0.06816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035218</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.095424</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.095424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.095424</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.15904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.15904</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         나는      중이다        있다     예정이다       공간에   작업       나의         그  \\\n",
       "0  0.025156  0.06816  0.000000  0.00000  0.000000  0.0  0.06816  0.000000   \n",
       "1  0.035218  0.00000  0.095424  0.00000  0.095424  0.0  0.00000  0.095424   \n",
       "2  0.000000  0.00000  0.000000  0.15904  0.000000  0.0  0.00000  0.000000   \n",
       "\n",
       "       내일도     공간이며      여기는  \n",
       "0  0.00000  0.06816  0.06816  \n",
       "1  0.00000  0.00000  0.00000  \n",
       "2  0.15904  0.00000  0.00000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF를 구하기 위한 함수 정의\n",
    "def getTFIDF(temp_dict, temp_idf):\n",
    "    tmp = {}\n",
    "    for strword, cntword  in temp_dict.items():\n",
    "        tmp[strword] = cntword*temp_idf[strword]\n",
    "    return tmp\n",
    "\n",
    "# 해당 문서의 TF단어와 IDF로 계산된 전체 단어와 합산\n",
    "text1_idfdict = getTFIDF(text1_tfDict, idf_dict)\n",
    "text2_idfdict = getTFIDF(text2_tfDict, idf_dict)\n",
    "text3_idfdict = getTFIDF(text3_tfDict, idf_dict)\n",
    "\n",
    "# 데이터 프레임으로 전환\n",
    "tfidf_df = pd.DataFrame([text1_idfdict, text2_idfdict,text3_idfdict ])\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지9 텍스트 데이터 수집(9)\n",
    "\n",
    "* sklearn을 활용하여 TF, DF, TF-IDF 계산\n",
    "  - sklearn의 TF-IDF는 1개 문자는 자동으로 제외\n",
    "  - IDF의 '0'반환을 처리하기 위해 가중치 +1이 적용\n",
    "  - 불용어처리, 최소/최대빈도, 분석기준(단어, 글자) 정의 및 다양한 파라미터 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_corpus</th>\n",
       "      <th>공간에</th>\n",
       "      <th>공간이며</th>\n",
       "      <th>나는</th>\n",
       "      <th>나의</th>\n",
       "      <th>내일도</th>\n",
       "      <th>여기는</th>\n",
       "      <th>예정이다</th>\n",
       "      <th>있다</th>\n",
       "      <th>작업</th>\n",
       "      <th>중이다</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>여기는 나의 작업 공간이며 나는 작업 중이다</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409146</td>\n",
       "      <td>0.311166</td>\n",
       "      <td>0.409146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483296</td>\n",
       "      <td>0.409146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나는 그 작업 공간에 있다</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>내일도 작업 예정이다</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text_corpus       공간에      공간이며        나는        나의       내일도  \\\n",
       "0  여기는 나의 작업 공간이며 나는 작업 중이다  0.000000  0.409146  0.311166  0.409146  0.000000   \n",
       "1            나는 그 작업 공간에 있다  0.584483  0.000000  0.444514  0.000000  0.000000   \n",
       "2               내일도 작업 예정이다  0.000000  0.000000  0.000000  0.000000  0.652491   \n",
       "\n",
       "        여기는      예정이다        있다        작업       중이다  \n",
       "0  0.409146  0.000000  0.000000  0.483296  0.409146  \n",
       "1  0.000000  0.000000  0.584483  0.345205  0.000000  \n",
       "2  0.000000  0.652491  0.000000  0.385372  0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 분석을 위해 수집된 말뭉치(Corpus)를 입력\n",
    "text_corpus = ['여기는 나의 작업 공간이며 나는 작업 중이다', '나는 그 작업 공간에 있다', '내일도 작업 예정이다' ]\n",
    "\n",
    "# 입력된 문서와 분석결과를 직관적으로 분석하기 위해 전환처리\n",
    "df_text_corpus  = pd.DataFrame([text_corpus]).T\n",
    "# text_corpus을 컬럼명으로 지정\n",
    "df_text_corpus.columns=['text_corpus']\n",
    "\n",
    "# 사이키런의 TfidfVectorizer를 생성하고 코퍼스를 전환처리\n",
    "tfidf_o = TfidfVectorizer()\n",
    "tfidf_dense = tfidf_o.fit_transform(df_text_corpus['text_corpus']).todense()\n",
    "words_list = tfidf_o.get_feature_names()\n",
    "\n",
    "# 데이터 프레임으로 전환\n",
    "df_text_corpus = df_text_corpus.join(pd.DataFrame(tfidf_dense, columns=words_list))\n",
    "df_text_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지10 텍스트 데이터 수집(10)\n",
    "\n",
    "* 모델기반의 클러스터링을 위한 k-Means 적용예제(1)\n",
    "* K-Means\n",
    " - 주어진 데이터를 K개의 클러스터로 묶는 알고리즘\n",
    " - 많은 양의 텍스트 데이터를 분류하여 적정 코퍼스구성을 위해 사용\n",
    "* K-Means 적용시 고려사항\n",
    " - 중심점에 따라 클러스터가 민감하게 변함\n",
    " - k의 개수를 선정하는 문제 존재\n",
    " - 적정 k(클러스터링 개수)의 산정은 Elbow, Silhouette Method 등 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지11 텍스트 데이터 수집(11)\n",
    "\n",
    "* 모델기반의 클러스터링을 위한 k-Means 적용예제(2)\n",
    " - 경제와 영화 관련 뉴스 제목을 군집의 개수 2개로 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 분석에 필요한 말뭉치(corpus) 정의\n",
    "documents = [\"한은 저유가 당분간 계속 주요국 물가 하방 압력\",\n",
    "             \"경총 국민 절반 이상이 동결 요구\",\n",
    "             \"경제 바닥 통과 기대 강화\",\n",
    "             \"도시 가스 물가 향상 기여\",\n",
    "             \"예측 불가능한 하늘에 도전했던 사람들 영화\",\n",
    "             \"전주 국제 영화 상영작\",\n",
    "             \"백상 예술 대상 영화 감독 봉준호\",\n",
    "             \"한번도 본적 없는 새로운 액션 영화\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# k-means++ 알고리즘을 적용, k개는 2개로 선정\n",
    "# init은 초기화 방법으로 random과 k-means++ 선택 가능\n",
    "# max_iter는 최대 반혹 횟수\n",
    "# n_init는 초기 중심 위치 시도 횟수, 기본은 10으로 사용\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=10)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유닛2, 페이지11 텍스트 데이터 수집(11)\n",
    "\n",
    "* 모델기반의 클러스터링을 위한 k-Means 적용예제(3)\n",
    " - 2개의 그룹의 주요 키워드와 새로운 뉴스제목의 그룹을 예측분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " 물가\n",
      " 향상\n",
      " 기여\n",
      " 도시\n",
      " 가스\n",
      " 통과\n",
      " 강화\n",
      " 바닥\n",
      " 기대\n",
      " 경제\n",
      "Cluster 1:\n",
      " 영화\n",
      " 상영작\n",
      " 전주\n",
      " 국제\n",
      " 도전했던\n",
      " 대상\n",
      " 백상\n",
      " 본적\n",
      " 봉준호\n",
      " 사람들\n",
      "\n",
      "\n",
      "Prediction\n",
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"서울 환경 영화 공동 주최\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"세계 경제 물가 침체 예상\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
