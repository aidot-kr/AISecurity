{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "7.ngram.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aidot-kr/AISecurity/blob/master/7_ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2mDpfmnB99S"
      },
      "source": [
        "## 7. ngram의 적용사례\n",
        "\n",
        " 1) NLTK의 N-gram 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEwVwVNnCHzu",
        "outputId": "82c138cb-5f79-4b51-c8f4-184c648ffc78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "!pip3 install konlpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.4MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.0MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 43.8MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: beautifulsoup4, tweepy, JPype1, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "A6dsmPepB99T",
        "outputId": "889fbabe-d9e8-4fe2-f0aa-4bf77078aa78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.util import ngrams\n",
        " \n",
        "# 문장에서 n-gram을 추출하는 함수\n",
        "def extract_ngrams(data, num):\n",
        "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        " \n",
        "data = '자전거를 좋아하는 사람은 산에서 타는 MTB 자전거를 선호한다'\n",
        " \n",
        "print(\"1-gram: \", extract_ngrams(data, 1))\n",
        "print(\"2-gram: \", extract_ngrams(data, 2))\n",
        "print(\"3-gram: \", extract_ngrams(data, 3))\n",
        "print(\"4-gram: \", extract_ngrams(data, 4))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "1-gram:  ['자전거를', '좋아하는', '사람은', '산에서', '타는', 'MTB', '자전거를', '선호한다']\n",
            "2-gram:  ['자전거를 좋아하는', '좋아하는 사람은', '사람은 산에서', '산에서 타는', '타는 MTB', 'MTB 자전거를', '자전거를 선호한다']\n",
            "3-gram:  ['자전거를 좋아하는 사람은', '좋아하는 사람은 산에서', '사람은 산에서 타는', '산에서 타는 MTB', '타는 MTB 자전거를', 'MTB 자전거를 선호한다']\n",
            "4-gram:  ['자전거를 좋아하는 사람은 산에서', '좋아하는 사람은 산에서 타는', '사람은 산에서 타는 MTB', '산에서 타는 MTB 자전거를', '타는 MTB 자전거를 선호한다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Kr6j1zB99X"
      },
      "source": [
        "2) TextBlob를 사용한 N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "hvrfsmAMB99Y",
        "outputId": "014f626a-dd78-4268-a65e-fab1fa002fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from textblob import TextBlob\n",
        " \n",
        "# 문장에서 n-gram을 추출하는 함수\n",
        "def extract_ngrams(data, num):\n",
        "    n_grams = TextBlob(data).ngrams(num)\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        " \n",
        "data = '자전거를 좋아하는 사람은 산에서 타는 MTB 자전거를 선호한다'\n",
        " \n",
        "print(\"1-gram: \", extract_ngrams(data, 1))\n",
        "print(\"2-gram: \", extract_ngrams(data, 2))\n",
        "print(\"3-gram: \", extract_ngrams(data, 3))\n",
        "print(\"4-gram: \", extract_ngrams(data, 4))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-gram:  ['자전거를', '좋아하는', '사람은', '산에서', '타는', 'MTB', '자전거를', '선호한다']\n",
            "2-gram:  ['자전거를 좋아하는', '좋아하는 사람은', '사람은 산에서', '산에서 타는', '타는 MTB', 'MTB 자전거를', '자전거를 선호한다']\n",
            "3-gram:  ['자전거를 좋아하는 사람은', '좋아하는 사람은 산에서', '사람은 산에서 타는', '산에서 타는 MTB', '타는 MTB 자전거를', 'MTB 자전거를 선호한다']\n",
            "4-gram:  ['자전거를 좋아하는 사람은 산에서', '좋아하는 사람은 산에서 타는', '사람은 산에서 타는 MTB', '산에서 타는 MTB 자전거를', '타는 MTB 자전거를 선호한다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5GAUz_5B99a"
      },
      "source": [
        "3) 빈도 리스트를 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f0KIkjoB99b",
        "outputId": "a63479d7-c408-478e-973a-06ab959c46ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import operator\n",
        "#n-gram 빈도 리스트 생성\n",
        "def make_freqlist(ngrams):\n",
        "  freqlist = {}\n",
        " \n",
        "  for ngram in ngrams:\n",
        "    if (ngram in freqlist):\n",
        "      freqlist[ngram] += 1\n",
        "    else:\n",
        "      freqlist[ngram] = 1\n",
        "   \n",
        "  return freqlist\n",
        "\n",
        "ngrams = extract_ngrams(data, 1)\n",
        "freqlist = make_freqlist(ngrams)\n",
        "sorted_freqlist = sorted(freqlist.items(), key=operator.itemgetter(1),reverse=True)\n",
        "print(sorted_freqlist)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('자전거를', 2), ('좋아하는', 1), ('사람은', 1), ('산에서', 1), ('타는', 1), ('MTB', 1), ('선호한다', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wtdJMKsB99d"
      },
      "source": [
        "4) 한글 형태소 분석기를 사용한 ngram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fLgNWkJGB99e",
        "outputId": "d57dba17-6bb4-4c59-b271-aa03dbf74ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        " \n",
        "# 문장에서 n-gram을 추출하는 함수\n",
        "def extract_ngrams(data, num):\n",
        "    n_grams = ngrams(okt.morphs(data), num) # 텍스트를 형태소 단위로 구분\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        " \n",
        "data = '자전거를 좋아하지 않는 사람은 산에서 타는 MTB 자전거를 싫어한다'\n",
        " \n",
        "print(\"1-gram: \", extract_ngrams(data, 1))\n",
        "print(\"2-gram: \", extract_ngrams(data, 2))\n",
        "print(\"3-gram: \", extract_ngrams(data, 3))\n",
        "print(\"4-gram: \", extract_ngrams(data, 4))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-gram:  ['자전거', '를', '좋아하지', '않는', '사람', '은', '산', '에서', '타는', 'MTB', '자전거', '를', '싫어한다']\n",
            "2-gram:  ['자전거 를', '를 좋아하지', '좋아하지 않는', '않는 사람', '사람 은', '은 산', '산 에서', '에서 타는', '타는 MTB', 'MTB 자전거', '자전거 를', '를 싫어한다']\n",
            "3-gram:  ['자전거 를 좋아하지', '를 좋아하지 않는', '좋아하지 않는 사람', '않는 사람 은', '사람 은 산', '은 산 에서', '산 에서 타는', '에서 타는 MTB', '타는 MTB 자전거', 'MTB 자전거 를', '자전거 를 싫어한다']\n",
            "4-gram:  ['자전거 를 좋아하지 않는', '를 좋아하지 않는 사람', '좋아하지 않는 사람 은', '않는 사람 은 산', '사람 은 산 에서', '은 산 에서 타는', '산 에서 타는 MTB', '에서 타는 MTB 자전거', '타는 MTB 자전거 를', 'MTB 자전거 를 싫어한다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "I17t157PB99f",
        "outputId": "a9cc7692-5e08-4d6b-ee48-e2e25b6a3aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ngrams = extract_ngrams(data, 1)\n",
        "freqlist = make_freqlist(ngrams)\n",
        "sorted_freqlist = sorted(freqlist.items(), key=operator.itemgetter(1),reverse=True)\n",
        "print(sorted_freqlist)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('자전거', 2), ('를', 2), ('좋아하지', 1), ('않는', 1), ('사람', 1), ('은', 1), ('산', 1), ('에서', 1), ('타는', 1), ('MTB', 1), ('싫어한다', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoO2sBr2B99h"
      },
      "source": [
        "5) bigram 언어모델의 확률 계산\n",
        " - 바로 앞 1개(k=1)의 단어 조합의 출현빈도를 계산하여 확률을 추정하는 모형"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehnTxcs8B99i"
      },
      "source": [
        "from nltk import bigrams, word_tokenize\n",
        "from nltk.util import ngrams \n",
        "\n",
        "sentence = \"자전거를 좋아하는 사람은 산에서 타는 MTB 자전거를 선호하고, \\\n",
        "    자전거를 좋아하지 않는 사람은 산에서 타는 MTB 자전거를 싫어한다\"\n",
        "tokens = word_tokenize(sentence)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "4V8Jq2DEB99k",
        "outputId": "9d47af17-bd85-4ac1-a678-83be9179ecba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "# 조건부 확률을 추정할 때는 모든 문장에 문장의 시작과 끝을 나타내는 별도의 토큰을 추가\n",
        "bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"ST\", right_pad_symbol=\"EN\")\n",
        "for t in bigram:\n",
        "    print(t)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('ST', '자전거를')\n",
            "('자전거를', '좋아하는')\n",
            "('좋아하는', '사람은')\n",
            "('사람은', '산에서')\n",
            "('산에서', '타는')\n",
            "('타는', 'MTB')\n",
            "('MTB', '자전거를')\n",
            "('자전거를', '선호하고')\n",
            "('선호하고', ',')\n",
            "(',', '자전거를')\n",
            "('자전거를', '좋아하지')\n",
            "('좋아하지', '않는')\n",
            "('않는', '사람은')\n",
            "('사람은', '산에서')\n",
            "('산에서', '타는')\n",
            "('타는', 'MTB')\n",
            "('MTB', '자전거를')\n",
            "('자전거를', '싫어한다')\n",
            "('싫어한다', 'EN')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI4bTfyMB99m"
      },
      "source": [
        "6) 조건부 확률의 추정\n",
        " - ConditionalFreqDist 클래스로 각 문맥별 단어 빈도를 측정\n",
        " - ConditionalProbDist 클래스를 사용하면 조건부 확률을 추정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB_SnJEEB99m"
      },
      "source": [
        "from nltk import ConditionalFreqDist # 조건부 확률을 추정함수\n",
        "\n",
        "bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"ST\", right_pad_symbol=\"EN\")\n",
        "cfd = ConditionalFreqDist([(k[0], k[1]) for k in bigram])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1_CRjsIB99o",
        "outputId": "f7f2e77b-b361-4028-da3e-432409cfa617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# ConditionalFreqDist 에 할당된 단어 목록 조회\n",
        "print(cfd.conditions())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ST', '자전거를', '좋아하는', '사람은', '산에서', '타는', 'MTB', '선호하고', ',', '좋아하지', '않는', '싫어한다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ze91s7dGB99p",
        "outputId": "5e48186c-1c97-486b-b03f-d0406117a363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 아래의 단어 다음에 출현 가능한 top 5 단어(어절) 표출\n",
        "cfd['자전거를'].most_common(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('좋아하는', 1), ('선호하고', 1), ('좋아하지', 1), ('싫어한다', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvykMm6tB99v"
      },
      "source": [
        "7) 조건부 확률에 의한 빈도 추정\n",
        " - ConditionalProbDist 클래스에 MLEProbDist 클래스 팩토리를 인수로 넣어 빈도를 추정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jzgTBeHB99v"
      },
      "source": [
        "from nltk.probability import ConditionalProbDist, MLEProbDist\n",
        "cpd = ConditionalProbDist(cfd, MLEProbDist)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwENBvrLB99z",
        "outputId": "964218d4-1aa1-4e5c-e86a-d0084a6dd837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cpd[\"자전거를\"].prob(\"좋아하는\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc3ysuGZB993",
        "outputId": "3ad67635-33b3-48f7-956b-6121eb4d1159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cpd[\"산에서\"].prob(\"타는\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLay_nwyB997",
        "outputId": "d88ed54e-aeab-4e8e-ac72-916a8d15fbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cpd[\"산에서\"].prob(\"선호하고\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeTlOmsgB999"
      },
      "source": [
        "8) 전체 문장의 확률 계산\n",
        " - 전체 문장의 확률은 조건부 확률의 곱으로 계산\n",
        " - P(ST I am a boy. EN)=P(I|ST)⋅P(am|I)⋅P(a|am)⋅P(boy|a)⋅P(.|boy)⋅P(EN|.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPddpNs7B99-"
      },
      "source": [
        "# 학습data\n",
        "# sentence = \"자전거를 좋아하는 사람은 산에서 타는 MTB 자전거를 선호하고, \\\n",
        "#    자전거를 좋아하지 않는 사람은 산에서 타는 MTB 자전거를 싫어한다\"\n",
        "\n",
        "import numpy as np\n",
        "def sentence_score(s):\n",
        "    p = 0.0\n",
        "    for i in range(len(s) - 1):\n",
        "        c = s[i]\n",
        "        w = s[i + 1]\n",
        "        p += np.log(cpd[c].prob(w) + np.finfo(float).eps)               \n",
        "        \n",
        "    return np.exp(p)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mW3eubrB9-A",
        "outputId": "2959fb16-f8b6-4ed3-8aaf-49be98077e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_sentence = [\"자전거를\", \"좋아하는\", \"사람은\"]\n",
        "sentence_score(test_sentence)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2500000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSK9UBwTB9-C",
        "outputId": "bc1ac551-a6c5-408b-8225-7d0885b1c452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_sentence = [\"좋아하는\", \"산에서\", \"타는\"]\n",
        "sentence_score(test_sentence)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2204460492503185e-16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgQLzkYBB9-F"
      },
      "source": [
        "9) Naver 영화리뷰 코퍼스를 활용한 언어모델 구축 (1)\n",
        " - 참고DataSet: 네이버 영화리뷰, 해당 폴더에서 ratings.txt 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1mem0eYSugm",
        "outputId": "fc0e8027-050f-4f56-f0eb-033a419630f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivC9e7s4Svz3",
        "outputId": "754cd23e-a016-452a-a646-c081ab08f662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/AISecurity"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AISecurity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIy4_xMYS-fO",
        "outputId": "ccdecb00-bc53-43cd-91ae-412e9b93494f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.TFIDF.ipynb           5.Word2Vec-FastText.ipynb  ratings.txt\n",
            "3.SimpleCrawling.ipynb  6.Similarity.ipynb         Sample.ipynb\n",
            "4_MeCab.ipynb           6.TopicModeling_bak.ipynb  spam.csv\n",
            "4_Pre_Processing.ipynb  6.TopicModeling.ipynb\n",
            "5.OneHotEncode.ipynb    7.ngram.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uq2VZPiB9-F"
      },
      "source": [
        "# ratings.txt가 있는 파일경로 구성\n",
        "# import os\n",
        "# os.getcwd()\n",
        "# str_path = '/Users'\n",
        "# os.chdir(str_path)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7oDiuw4B9-I",
        "outputId": "024553a7-d823-4bf6-b178-f59ad3b1917d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import codecs\n",
        "with codecs.open(\"ratings.txt\", encoding='utf-8') as f:\n",
        "    data = [line.split('\\t') for line in f.read().splitlines()]\n",
        "    data = data[1:]   # header 제외\n",
        "\n",
        "docs = [row[1] for row in data]\n",
        "len(docs)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVHSZ7-hB9-K"
      },
      "source": [
        "#import warnings\n",
        "#warnings.simplefilter(\"ignore\")\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "tagger = Okt()\n",
        "\n",
        "def tokenize(doc):\n",
        "    tokens = ['/'.join(t) for t in tagger.pos(doc)]\n",
        "    return tokens"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQCkEFvqB9-L",
        "outputId": "3eccd28f-ae87-4f63-eb13-6c383c0d3137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm #진행상태를 표현하는 라이브러리\n",
        "sentences = []\n",
        "for d in tqdm(docs):\n",
        "    tokens = tokenize(d)\n",
        "    bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"SS\", right_pad_symbol=\"SE\")\n",
        "    sentences += [t for t in bigram]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [11:25<00:00, 291.68it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFa_Fuv4B9-N"
      },
      "source": [
        "10) 조건부 확률에 의한 빈도 추정\n",
        " - ConditionalProbDist 클래스에 MLEProbDist 클래스 팩토리를 인수로 넣어 빈도를 추정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXX5112BB9-O"
      },
      "source": [
        "cfd = ConditionalFreqDist(sentences)\n",
        "cpd = ConditionalProbDist(cfd, MLEProbDist)\n",
        "\n",
        "def korean_most_common(c, n, pos=None):\n",
        "    if pos is None:\n",
        "        return cfd[tokenize(c)[0]].most_common(n)\n",
        "    else:\n",
        "        return cfd[\"/\".join([c, pos])].most_common(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20p7J8wgB9-Q",
        "outputId": "36f9d751-b1fd-4216-a6d9-e49238726230"
      },
      "source": [
        "korean_most_common(\"폴리스\", 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('스토리/Noun', 9), ('아카데미/Noun', 1), ('에서/Josa', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb0WP5ZLB9-S",
        "outputId": "56721922-3f2c-4d23-a9d2-1ac49583b1cf"
      },
      "source": [
        "korean_most_common(\"전쟁\", 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('의/Josa', 108),\n",
              " ('을/Josa', 47),\n",
              " ('이/Josa', 41),\n",
              " ('에/Josa', 35),\n",
              " ('은/Josa', 33),\n",
              " ('영화/Noun', 29),\n",
              " ('과/Josa', 19),\n",
              " ('으로/Josa', 15),\n",
              " ('./Punctuation', 13),\n",
              " ('씬/Noun', 11)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvNXGpC4B9-V"
      },
      "source": [
        "11) 문장 생성\n",
        " - 영화리뷰 모델을 활용하여 문장을 생성할 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xbe-lNcB9-V"
      },
      "source": [
        "def korean_generate_sentence(seed=None, debug=False):\n",
        "    if seed is not None:\n",
        "        import random\n",
        "        random.seed(seed)\n",
        "    c = \"SS\"\n",
        "    sentence = []\n",
        "    while True:\n",
        "        if c not in cpd:\n",
        "            break\n",
        "            \n",
        "        w = cpd[c].generate()\n",
        "\n",
        "        if w == \"SE\":\n",
        "            break\n",
        "\n",
        "        w2 = w.split(\"/\")[0]\n",
        "        pos = w.split(\"/\")[1]\n",
        "\n",
        "        if c == \"SS\":\n",
        "            sentence.append(w2.title())\n",
        "        elif c in [\"`\", \"\\\"\", \"'\", \"(\"]:\n",
        "            sentence.append(w2)\n",
        "        elif w2 in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
        "            sentence.append(w2)\n",
        "        elif pos in [\"Josa\", \"Punctuation\", \"Suffix\"]:\n",
        "            sentence.append(w2)\n",
        "        elif w in [\"임/Noun\", \"것/Noun\", \"는걸/Noun\", \"릴때/Noun\",\n",
        "                   \"되다/Verb\", \"이다/Verb\", \"하다/Verb\", \"이다/Adjective\"]:\n",
        "            sentence.append(w2)\n",
        "        else:\n",
        "            sentence.append(\" \" + w2)\n",
        "        c = w\n",
        "\n",
        "        if debug:\n",
        "            print(w)\n",
        "\n",
        "    return \"\".join(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndUcKgs4B9-X",
        "outputId": "6d760618-cdd4-4810-fd5c-21c9488b5af7"
      },
      "source": [
        "korean_generate_sentence(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'그다지 별로'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVWO_q_6B9-Z",
        "outputId": "5344bde6-9516-41c8-df93-97d89a2f9fa6"
      },
      "source": [
        "korean_generate_sentence(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'이영화 아닌줄 알았음 ㅋㅋ 므흣합니다. 상대가 상당히 많았지.. 지루함은 영어 발음과 유치한 산만함 그 유명한 영화 였습니다'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH6ytqycB9-b",
        "outputId": "ab7c48db-b9c5-44a7-dddf-d92bcfdfb3aa"
      },
      "source": [
        "korean_generate_sentence(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'액션의 최고봉.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQttHcgzB9-d",
        "outputId": "1eea5d49-1fb2-49e0-aae3-a4771f95ee4f"
      },
      "source": [
        "korean_generate_sentence(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'슈퍼 즈 중에서도 여전히 재밌다 damn hard. 배우들은 액션으로만 보시면 후회한 연출 후지고 아이들 많구만 ㅠㅠ 이 걸 그냥 지루한 시즌 2) 추천 해요~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    }
  ]
}